{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fb5134c",
   "metadata": {},
   "source": [
    "## **Library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "efdebad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "import tqdm\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import librosa\n",
    "import librosa.display\n",
    "import soundfile as sf\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from audiomentations import Compose, AddGaussianNoise, TimeStretch, PitchShift, Shift\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential, layers, models, optimizers, callbacks, mixed_precision\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "920ff49f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "# check gpu availability\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "        print(f\"{len(gpus)} Physical GPUs, {len(logical_gpus)} Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d7195e",
   "metadata": {},
   "source": [
    "## **Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8cfebb87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total WAV files found: 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\loq\\anaconda3\\envs\\tf-audio-gpu\\lib\\site-packages\\librosa\\core\\intervals.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_filename\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: 01-01-01-01.wav, Duration: 3.00 seconds, Sample Rate: 44100 Hz\n",
      "File: 01-01-01-02.wav, Duration: 3.00 seconds, Sample Rate: 44100 Hz\n",
      "File: 01-01-01-03.wav, Duration: 3.00 seconds, Sample Rate: 44100 Hz\n",
      "File: 01-01-02-01.wav, Duration: 3.00 seconds, Sample Rate: 44100 Hz\n",
      "File: 01-01-02-02.wav, Duration: 3.00 seconds, Sample Rate: 44100 Hz\n",
      "\n",
      "Loading all audio files to analyze durations...\n",
      "\n",
      "Duration Statistics:\n",
      "Total files: 300\n",
      "Min duration: 3.00 seconds\n",
      "Max duration: 3.80 seconds\n",
      "Mean duration: 3.10 seconds\n",
      "Median duration: 3.00 seconds\n"
     ]
    }
   ],
   "source": [
    "audio_folder = r\"C:\\Users\\Salim\\Kuliah\\Semester 5\\Jaringan Syaraf Tiruan\\Project\\Project-JST\\Data\\IndoWaveSentiment\"\n",
    "\n",
    "actor_dirs = [f'Actor_{str(i).zfill(2)}' for i in range(1, 11)]\n",
    "wav_files = []\n",
    "for actor in actor_dirs:\n",
    "    actor_path = os.path.join(audio_folder, actor, '*.wav')\n",
    "    wav_files.extend(glob.glob(actor_path))\n",
    "print(f\"Total WAV files found: {len(wav_files)}\")\n",
    "\n",
    "# load all audio files and print their durations\n",
    "for file in wav_files[:5]:  # just load first 5 files for demonstration\n",
    "    audio, sr = librosa.load(file, sr=None)\n",
    "    duration = len(audio) / sr\n",
    "    print(f\"File: {os.path.basename(file)}, Duration: {duration:.2f} seconds, Sample Rate: {sr} Hz\")\n",
    "\n",
    "# Print statistics about all durations\n",
    "print(\"\\nLoading all audio files to analyze durations...\")\n",
    "all_durations = []\n",
    "for file in wav_files:\n",
    "    audio, sr = librosa.load(file, sr=None)\n",
    "    duration = len(audio) / sr\n",
    "    all_durations.append(duration)\n",
    "\n",
    "print(f\"\\nDuration Statistics:\")\n",
    "print(f\"Total files: {len(all_durations)}\")\n",
    "print(f\"Min duration: {min(all_durations):.2f} seconds\")\n",
    "print(f\"Max duration: {max(all_durations):.2f} seconds\")\n",
    "print(f\"Mean duration: {np.mean(all_durations):.2f} seconds\")\n",
    "print(f\"Median duration: {np.median(all_durations):.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f904dd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "SR = 22050               # sampling rate\n",
    "DURATION = 4.0           # target duration (seconds) -> semua file akan dipotong / dipadatkan\n",
    "N_MELS = 128             # mel bins (freq)\n",
    "N_FFT = 2048\n",
    "HOP_LENGTH = 512\n",
    "EPS = 1e-6\n",
    "BATCH_SIZE = 32\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# helper: load, pad/trim, compute log-mel spectrogram, normalize per-sample\n",
    "def file_to_log_mel(path, sr=SR, duration=DURATION, n_mels=N_MELS, n_fft=N_FFT, hop_length=HOP_LENGTH):\n",
    "    y, _sr = librosa.load(path, sr=sr, mono=True)\n",
    "    target_len = int(sr * duration)\n",
    "    if len(y) < target_len:\n",
    "        y = librosa.util.fix_length(y, size=target_len)   # pad with zeros\n",
    "    else:\n",
    "        y = y[:target_len]                                 # trim if longer\n",
    "    # mel spectrogram\n",
    "    mel = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels, power=2.0)\n",
    "    log_mel = librosa.power_to_db(mel, ref=np.max)\n",
    "    # normalize (mean-std) per sample\n",
    "    log_mel = (log_mel - np.mean(log_mel)) / (np.std(log_mel) + EPS)\n",
    "    return log_mel.astype(np.float32)   # shape: (n_mels, t_frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3feab1b",
   "metadata": {},
   "source": [
    "## **Augmentation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12e1d862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main path\n",
    "project_root = Path(r\"C:\\Users\\Salim\\Kuliah\\Semester 5\\Jaringan Syaraf Tiruan\\Project\\Project-JST\")\n",
    "base_dir = str(project_root / \"Data\" / \"IndoWaveSentiment\")\n",
    "output_base = str(project_root / \"Data\" / \"IndoWaveSentiment_Augmented\")\n",
    "\n",
    "# create folder if not exists\n",
    "os.makedirs(output_base, exist_ok=True)\n",
    "\n",
    "# Define augmentation pipeline\n",
    "augment = Compose([\n",
    "    AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.015, p=0.5),\n",
    "    TimeStretch(min_rate=0.8, max_rate=1.25, p=0.5),\n",
    "    PitchShift(min_semitones=-4, max_semitones=4, p=0.5),\n",
    "    Shift(min_shift=-0.5, max_shift=0.5, p=0.5)\n",
    "])\n",
    "\n",
    "for actor_folder in os.listdir(base_dir):\n",
    "    actor_path = os.path.join(base_dir, actor_folder)\n",
    "    if not os.path.isdir(actor_path):\n",
    "        continue\n",
    "\n",
    "    output_actor_path = os.path.join(output_base, actor_folder)\n",
    "    os.makedirs(output_actor_path, exist_ok=True)\n",
    "\n",
    "    for file_name in os.listdir(actor_path):\n",
    "        if file_name.endswith(\".wav\"):\n",
    "            file_path = os.path.join(actor_path, file_name)\n",
    "            samples, sr = sf.read(file_path)\n",
    "\n",
    "            if samples.dtype != np.float32:\n",
    "                samples = samples.astype(np.float32)\n",
    "\n",
    "            # augment\n",
    "            augmented = augment(samples=samples, sample_rate=sr)\n",
    "\n",
    "            aug_name = file_name.replace(\".wav\", \"_aug.wav\")\n",
    "            output_path = os.path.join(output_actor_path, aug_name)\n",
    "            sf.write(output_path, augmented, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c8462c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total original files: 300\n",
      "Total augmented files: 300\n",
      "Total WAV files: 600\n",
      "['neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral']\n"
     ]
    }
   ],
   "source": [
    "# label dictionary\n",
    "label_map = {\n",
    "    '01': 'neutral',\n",
    "    '02': 'happy',\n",
    "    '03': 'surprise',\n",
    "    '04': 'disgust',\n",
    "    '05': 'disappointed'\n",
    "}\n",
    "\n",
    "# Update wav_files to include both original and augmented files\n",
    "wav_files_original = []\n",
    "for actor in actor_dirs:\n",
    "    actor_path = os.path.join(audio_folder, actor, '*.wav')\n",
    "    wav_files_original.extend(glob.glob(actor_path))\n",
    "\n",
    "wav_files_augmented = []\n",
    "for actor in actor_dirs:\n",
    "    actor_path = os.path.join(output_base, actor, '*_aug.wav')\n",
    "    wav_files_augmented.extend(glob.glob(actor_path))\n",
    "\n",
    "wav_files = wav_files_original + wav_files_augmented\n",
    "print(f\"Total original files: {len(wav_files_original)}\")\n",
    "print(f\"Total augmented files: {len(wav_files_augmented)}\")\n",
    "print(f\"Total WAV files: {len(wav_files)}\")\n",
    "\n",
    "def label_from_filename(filename):\n",
    "    \"\"\"\n",
    "    Extract emotion code from filename robustly.\n",
    "    Finds the first 2-digit token in the name that matches label_map keys.\n",
    "    \"\"\"\n",
    "    fname = os.path.basename(filename)\n",
    "    for code in re.findall(r'\\d{2}', fname):\n",
    "        if code in label_map:\n",
    "            return label_map[code]\n",
    "    return 'unknown'\n",
    "\n",
    "labels = [label_from_filename(f) for f in wav_files]\n",
    "print(labels[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f9cad4ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built dataset: (600, 128, 173, 1) labels: Counter({'neutral': 120, 'happy': 120, 'surprise': 120, 'disgust': 120, 'disappointed': 120})\n",
      "Classes found: ['disappointed' 'disgust' 'happy' 'neutral' 'surprise'] count: 5\n",
      "Splits: (480, 128, 173, 1) (60, 128, 173, 1) (60, 128, 173, 1)\n",
      "Class weights: {0: 0.96, 1: 1.0434782608695652, 2: 1.0, 3: 0.9795918367346939, 4: 1.0212765957446808}\n"
     ]
    }
   ],
   "source": [
    "X_list = []\n",
    "y_list = []\n",
    "X_files = []\n",
    "skipped = []\n",
    "\n",
    "for fp in wav_files:\n",
    "    lbl = label_from_filename(fp)\n",
    "    if lbl == 'unknown':\n",
    "        skipped.append(fp)\n",
    "        continue\n",
    "    try:\n",
    "        spec = file_to_log_mel(fp)        # (n_mels, t_frames)\n",
    "        X_list.append(spec)\n",
    "        y_list.append(lbl)\n",
    "        X_files.append(fp)\n",
    "    except Exception as e:\n",
    "        skipped.append(fp)\n",
    "        print(\"Skipped\", fp, \":\", e)\n",
    "\n",
    "if len(X_list) == 0:\n",
    "    raise RuntimeError(\"No valid spectrograms. Check filenames and label_map.\")\n",
    "\n",
    "# Stack and add channel dim for Conv2D\n",
    "X = np.stack(X_list, axis=0).astype(np.float32)   # (N, n_mels, t_frames)\n",
    "X = np.expand_dims(X, -1)                         # (N, n_mels, t_frames, 1)\n",
    "y = np.array(y_list)\n",
    "\n",
    "print(\"Built dataset:\", X.shape, \"labels:\", Counter(y))\n",
    "if skipped:\n",
    "    print(\"Skipped files:\", len(skipped), \"examples:\", skipped[:5])\n",
    "\n",
    "# Encode labels -> expect 5 classes\n",
    "le = LabelEncoder()\n",
    "y_enc = le.fit_transform(y)\n",
    "print(\"Classes found:\", le.classes_, \"count:\", len(le.classes_))\n",
    "if len(le.classes_) != 5:\n",
    "    print(\"Warning: expected 5 emotion classes. Verify label_map and filenames.\")\n",
    "\n",
    "# group-aware split\n",
    "def group_key(path):\n",
    "    # Group original and augmented versions together\n",
    "    fname = os.path.basename(path)\n",
    "    stem = fname.replace('_aug', '').replace('.wav', '')\n",
    "    return stem\n",
    "\n",
    "groups = np.array([group_key(fp) for fp in X_files])\n",
    "\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.20, random_state=RANDOM_STATE)\n",
    "train_idx, temp_idx = next(gss.split(X, y_enc, groups))\n",
    "\n",
    "X_train, y_train = X[train_idx], y_enc[train_idx]\n",
    "X_temp, y_temp = X[temp_idx], y_enc[temp_idx]\n",
    "groups_temp = groups[temp_idx]\n",
    "\n",
    "gss2 = GroupShuffleSplit(n_splits=1, test_size=0.50, random_state=RANDOM_STATE)\n",
    "val_idx, test_idx = next(gss2.split(X_temp, y_temp, groups_temp))\n",
    "\n",
    "X_val, y_val = X_temp[val_idx], y_temp[val_idx]\n",
    "X_test, y_test = X_temp[test_idx], y_temp[test_idx]\n",
    "\n",
    "print(\"Splits:\", X_train.shape, X_val.shape, X_test.shape)\n",
    "\n",
    "# Recompute class weights on y_train\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "class_weights = dict(enumerate(compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)))\n",
    "print(\"Class weights:\", class_weights)\n",
    "\n",
    "# Recreate tf.data datasets\n",
    "def make_ds(Xa, ya, batch=BATCH_SIZE, shuffle=False):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((Xa, ya))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=min(len(ya), 2048), seed=RANDOM_STATE)\n",
    "    return ds.batch(batch).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "train_ds = make_ds(X_train, y_train, batch=BATCH_SIZE, shuffle=True)\n",
    "val_ds = make_ds(X_val, y_val, batch=BATCH_SIZE, shuffle=False)\n",
    "test_ds = make_ds(X_test, y_test, batch=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e248e2",
   "metadata": {},
   "source": [
    "## **Feature Extraction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54b8e625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building VGGish feature extractor...\n",
      "Model: \"VGGish_Feature_Extractor\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1 (Conv2D)              (None, 128, 173, 64)      640       \n",
      "                                                                 \n",
      " pool1 (MaxPooling2D)        (None, 64, 86, 64)        0         \n",
      "                                                                 \n",
      " conv2 (Conv2D)              (None, 64, 86, 128)       73856     \n",
      "                                                                 \n",
      " pool2 (MaxPooling2D)        (None, 32, 43, 128)       0         \n",
      "                                                                 \n",
      " conv3_1 (Conv2D)            (None, 32, 43, 256)       295168    \n",
      "                                                                 \n",
      " conv3_2 (Conv2D)            (None, 32, 43, 256)       590080    \n",
      "                                                                 \n",
      " pool3 (MaxPooling2D)        (None, 16, 21, 256)       0         \n",
      "                                                                 \n",
      " conv4_1 (Conv2D)            (None, 16, 21, 512)       1180160   \n",
      "                                                                 \n",
      " conv4_2 (Conv2D)            (None, 16, 21, 512)       2359808   \n",
      "                                                                 \n",
      " pool4 (MaxPooling2D)        (None, 8, 10, 512)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 40960)             0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 4096)              167776256 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 4096)              0         \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " vggish_embedding (Dense)    (None, 128)               524416    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 189,581,696\n",
      "Trainable params: 189,581,696\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Extracting VGGish features...\n",
      "15/15 [==============================] - 11s 28ms/step\n",
      "2/2 [==============================] - 2s 1s/step\n",
      "2/2 [==============================] - 0s 32ms/step\n",
      "\n",
      "VGGish features shape:\n",
      "Train: (480, 128)\n",
      "Val: (60, 128)\n",
      "Test: (60, 128)\n",
      "\n",
      "Features saved to C:\\Users\\Salim\\Kuliah\\Semester 5\\Jaringan Syaraf Tiruan\\Project\\Project-JST\\Data\\vggish_features\n"
     ]
    }
   ],
   "source": [
    "# VGGish-inspired feature extractor\n",
    "def build_vggish_feature_extractor(input_shape):\n",
    "    \"\"\"\n",
    "    VGGish-inspired CNN for audio feature extraction.\n",
    "    Original VGGish uses 64x96 mel spectrograms, but we adapt to our input shape.\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        layers.Input(shape=input_shape),\n",
    "        \n",
    "        # Block 1\n",
    "        layers.Conv2D(64, (3,3), padding='same', activation='relu', name='conv1'),\n",
    "        layers.MaxPool2D((2,2), strides=(2,2), name='pool1'),\n",
    "        \n",
    "        # Block 2\n",
    "        layers.Conv2D(128, (3,3), padding='same', activation='relu', name='conv2'),\n",
    "        layers.MaxPool2D((2,2), strides=(2,2), name='pool2'),\n",
    "        \n",
    "        # Block 3\n",
    "        layers.Conv2D(256, (3,3), padding='same', activation='relu', name='conv3_1'),\n",
    "        layers.Conv2D(256, (3,3), padding='same', activation='relu', name='conv3_2'),\n",
    "        layers.MaxPool2D((2,2), strides=(2,2), name='pool3'),\n",
    "        \n",
    "        # Block 4\n",
    "        layers.Conv2D(512, (3,3), padding='same', activation='relu', name='conv4_1'),\n",
    "        layers.Conv2D(512, (3,3), padding='same', activation='relu', name='conv4_2'),\n",
    "        layers.MaxPool2D((2,2), strides=(2,2), name='pool4'),\n",
    "        \n",
    "        # Flatten and FC layers for embedding\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(4096, activation='relu', name='fc1'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(4096, activation='relu', name='fc2'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(128, activation='relu', name='vggish_embedding'),  # VGGish embedding layer\n",
    "    ], name='VGGish_Feature_Extractor')\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Extract VGGish features for all splits\n",
    "print(\"Building VGGish feature extractor...\")\n",
    "vggish_extractor = build_vggish_feature_extractor(input_shape=X_train.shape[1:])\n",
    "vggish_extractor.summary()\n",
    "\n",
    "print(\"\\nExtracting VGGish features...\")\n",
    "X_train_vggish = vggish_extractor.predict(X_train, batch_size=BATCH_SIZE, verbose=1)\n",
    "X_val_vggish = vggish_extractor.predict(X_val, batch_size=BATCH_SIZE, verbose=1)\n",
    "X_test_vggish = vggish_extractor.predict(X_test, batch_size=BATCH_SIZE, verbose=1)\n",
    "\n",
    "print(f\"\\nVGGish features shape:\")\n",
    "print(f\"Train: {X_train_vggish.shape}\")\n",
    "print(f\"Val: {X_val_vggish.shape}\")\n",
    "print(f\"Test: {X_test_vggish.shape}\")\n",
    "\n",
    "# Save extracted features (optional)\n",
    "save_features = True\n",
    "if save_features:\n",
    "    features_dir = project_root / \"Data\" / \"vggish_features\"\n",
    "    os.makedirs(features_dir, exist_ok=True)\n",
    "    \n",
    "    np.save(str(features_dir / \"X_train_vggish.npy\"), X_train_vggish)\n",
    "    np.save(str(features_dir / \"X_val_vggish.npy\"), X_val_vggish)\n",
    "    np.save(str(features_dir / \"X_test_vggish.npy\"), X_test_vggish)\n",
    "    np.save(str(features_dir / \"y_train.npy\"), y_train)\n",
    "    np.save(str(features_dir / \"y_val.npy\"), y_val)\n",
    "    np.save(str(features_dir / \"y_test.npy\"), y_test)\n",
    "    \n",
    "    print(f\"\\nFeatures saved to {features_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087289d2",
   "metadata": {},
   "source": [
    "## **Modelling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bd5edbb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mixed precision enabled.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    mixed_precision.set_global_policy('mixed_float16')\n",
    "    print(\"Mixed precision enabled.\")\n",
    "except Exception as e:\n",
    "    print(\"Mixed precision not enabled:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "611911b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (128, 173, 1) Num classes: 5\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 128, 173, 32)      320       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 128, 173, 32)     128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 64, 86, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 64, 86, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 64, 86, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 32, 43, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " permute (Permute)           (None, 43, 32, 64)        0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 43, 2048)          0         \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 43, 256)          2229248   \n",
      " l)                                                              \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 128)              164352    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,429,957\n",
      "Trainable params: 2,429,765\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = X_train.shape[1:]   # (n_mels, t_frames, 1)\n",
    "num_classes = len(np.unique(y_train))\n",
    "print(\"Input shape:\", input_shape, \"Num classes:\", num_classes)\n",
    "\n",
    "mel_down = input_shape[0] // 4    # two 2x2 pools on frequency\n",
    "feat_per_step = mel_down * 64     # 64 filters after second Conv2D\n",
    "\n",
    "model = Sequential([\n",
    "    layers.Input(shape=input_shape),\n",
    "    layers.Conv2D(32, (3,3), padding='same', activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPool2D((2,2)),\n",
    "\n",
    "    layers.Conv2D(64, (3,3), padding='same', activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPool2D((2,2)),\n",
    "\n",
    "    # (mel/4, time/4, 64) -> (time/4, feat_per_step)\n",
    "    layers.Permute((2,1,3)),\n",
    "    layers.Reshape((-1, int(feat_per_step))),\n",
    "\n",
    "    layers.Bidirectional(layers.LSTM(128, return_sequences=True)),\n",
    "    layers.Bidirectional(layers.LSTM(64)),\n",
    "    layers.Dropout(0.4),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizers.Adam(3e-4),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "ckpt_path = \"cnn_bilstm_best.h5\"\n",
    "cbs = [\n",
    "    callbacks.ModelCheckpoint(ckpt_path, monitor='val_loss', save_best_only=True, verbose=1),\n",
    "    callbacks.EarlyStopping(monitor='val_loss', patience=12, restore_best_weights=True, verbose=1),\n",
    "    callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4, verbose=1),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1baed10a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 1.6128 - accuracy: 0.2313\n",
      "Epoch 1: val_loss improved from inf to 1.60046, saving model to cnn_bilstm_best.h5\n",
      "15/15 [==============================] - 19s 340ms/step - loss: 1.6128 - accuracy: 0.2313 - val_loss: 1.6005 - val_accuracy: 0.3500 - lr: 3.0000e-04\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 1.5411 - accuracy: 0.2979\n",
      "Epoch 2: val_loss improved from 1.60046 to 1.56751, saving model to cnn_bilstm_best.h5\n",
      "15/15 [==============================] - 2s 99ms/step - loss: 1.5411 - accuracy: 0.2979 - val_loss: 1.5675 - val_accuracy: 0.4333 - lr: 3.0000e-04\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 1.4575 - accuracy: 0.3729\n",
      "Epoch 3: val_loss improved from 1.56751 to 1.55736, saving model to cnn_bilstm_best.h5\n",
      "15/15 [==============================] - 1s 91ms/step - loss: 1.4575 - accuracy: 0.3729 - val_loss: 1.5574 - val_accuracy: 0.4167 - lr: 3.0000e-04\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 1.3491 - accuracy: 0.4583\n",
      "Epoch 4: val_loss improved from 1.55736 to 1.54069, saving model to cnn_bilstm_best.h5\n",
      "15/15 [==============================] - 1s 85ms/step - loss: 1.3491 - accuracy: 0.4583 - val_loss: 1.5407 - val_accuracy: 0.3500 - lr: 3.0000e-04\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 1.2699 - accuracy: 0.5146\n",
      "Epoch 5: val_loss did not improve from 1.54069\n",
      "15/15 [==============================] - 1s 74ms/step - loss: 1.2699 - accuracy: 0.5146 - val_loss: 1.5425 - val_accuracy: 0.3333 - lr: 3.0000e-04\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 1.1405 - accuracy: 0.5625\n",
      "Epoch 6: val_loss did not improve from 1.54069\n",
      "15/15 [==============================] - 1s 70ms/step - loss: 1.1405 - accuracy: 0.5625 - val_loss: 1.5542 - val_accuracy: 0.3000 - lr: 3.0000e-04\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 1.0449 - accuracy: 0.5667\n",
      "Epoch 7: val_loss did not improve from 1.54069\n",
      "15/15 [==============================] - 1s 75ms/step - loss: 1.0449 - accuracy: 0.5667 - val_loss: 1.5526 - val_accuracy: 0.2833 - lr: 3.0000e-04\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.8542 - accuracy: 0.7146\n",
      "Epoch 8: val_loss improved from 1.54069 to 1.50638, saving model to cnn_bilstm_best.h5\n",
      "15/15 [==============================] - 1s 89ms/step - loss: 0.8542 - accuracy: 0.7146 - val_loss: 1.5064 - val_accuracy: 0.3167 - lr: 3.0000e-04\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.6669 - accuracy: 0.7854\n",
      "Epoch 9: val_loss did not improve from 1.50638\n",
      "15/15 [==============================] - 1s 76ms/step - loss: 0.6669 - accuracy: 0.7854 - val_loss: 1.5145 - val_accuracy: 0.2833 - lr: 3.0000e-04\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4748 - accuracy: 0.8562\n",
      "Epoch 10: val_loss improved from 1.50638 to 1.45736, saving model to cnn_bilstm_best.h5\n",
      "15/15 [==============================] - 1s 89ms/step - loss: 0.4748 - accuracy: 0.8562 - val_loss: 1.4574 - val_accuracy: 0.2833 - lr: 3.0000e-04\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4807 - accuracy: 0.8479\n",
      "Epoch 11: val_loss improved from 1.45736 to 1.43060, saving model to cnn_bilstm_best.h5\n",
      "15/15 [==============================] - 1s 90ms/step - loss: 0.4807 - accuracy: 0.8479 - val_loss: 1.4306 - val_accuracy: 0.3000 - lr: 3.0000e-04\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4001 - accuracy: 0.8646\n",
      "Epoch 12: val_loss did not improve from 1.43060\n",
      "15/15 [==============================] - 1s 79ms/step - loss: 0.4001 - accuracy: 0.8646 - val_loss: 1.4620 - val_accuracy: 0.3333 - lr: 3.0000e-04\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.2627 - accuracy: 0.9479\n",
      "Epoch 13: val_loss did not improve from 1.43060\n",
      "15/15 [==============================] - 1s 75ms/step - loss: 0.2627 - accuracy: 0.9479 - val_loss: 1.4766 - val_accuracy: 0.2833 - lr: 3.0000e-04\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.1580 - accuracy: 0.9812\n",
      "Epoch 14: val_loss improved from 1.43060 to 1.40169, saving model to cnn_bilstm_best.h5\n",
      "15/15 [==============================] - 1s 84ms/step - loss: 0.1580 - accuracy: 0.9812 - val_loss: 1.4017 - val_accuracy: 0.3500 - lr: 3.0000e-04\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0823 - accuracy: 0.9875\n",
      "Epoch 15: val_loss did not improve from 1.40169\n",
      "15/15 [==============================] - 1s 72ms/step - loss: 0.0823 - accuracy: 0.9875 - val_loss: 1.4096 - val_accuracy: 0.3667 - lr: 3.0000e-04\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0610 - accuracy: 0.9917\n",
      "Epoch 16: val_loss improved from 1.40169 to 1.33431, saving model to cnn_bilstm_best.h5\n",
      "15/15 [==============================] - 1s 91ms/step - loss: 0.0610 - accuracy: 0.9917 - val_loss: 1.3343 - val_accuracy: 0.4333 - lr: 3.0000e-04\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0574 - accuracy: 0.9937\n",
      "Epoch 17: val_loss did not improve from 1.33431\n",
      "15/15 [==============================] - 1s 71ms/step - loss: 0.0574 - accuracy: 0.9937 - val_loss: 1.3874 - val_accuracy: 0.4500 - lr: 3.0000e-04\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.1355 - accuracy: 0.9708\n",
      "Epoch 18: val_loss did not improve from 1.33431\n",
      "15/15 [==============================] - 1s 69ms/step - loss: 0.1355 - accuracy: 0.9708 - val_loss: 1.4492 - val_accuracy: 0.3833 - lr: 3.0000e-04\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.1326 - accuracy: 0.9625\n",
      "Epoch 19: val_loss improved from 1.33431 to 1.26517, saving model to cnn_bilstm_best.h5\n",
      "15/15 [==============================] - 1s 83ms/step - loss: 0.1326 - accuracy: 0.9625 - val_loss: 1.2652 - val_accuracy: 0.5000 - lr: 3.0000e-04\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0638 - accuracy: 0.9854\n",
      "Epoch 20: val_loss improved from 1.26517 to 1.12767, saving model to cnn_bilstm_best.h5\n",
      "15/15 [==============================] - 1s 86ms/step - loss: 0.0638 - accuracy: 0.9854 - val_loss: 1.1277 - val_accuracy: 0.6000 - lr: 3.0000e-04\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0355 - accuracy: 1.0000\n",
      "Epoch 21: val_loss did not improve from 1.12767\n",
      "15/15 [==============================] - 1s 74ms/step - loss: 0.0355 - accuracy: 1.0000 - val_loss: 1.2808 - val_accuracy: 0.5167 - lr: 3.0000e-04\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0283 - accuracy: 0.9979\n",
      "Epoch 22: val_loss improved from 1.12767 to 1.02096, saving model to cnn_bilstm_best.h5\n",
      "15/15 [==============================] - 1s 85ms/step - loss: 0.0283 - accuracy: 0.9979 - val_loss: 1.0210 - val_accuracy: 0.6500 - lr: 3.0000e-04\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0245 - accuracy: 0.9958\n",
      "Epoch 23: val_loss did not improve from 1.02096\n",
      "15/15 [==============================] - 1s 75ms/step - loss: 0.0245 - accuracy: 0.9958 - val_loss: 1.1113 - val_accuracy: 0.6333 - lr: 3.0000e-04\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0205 - accuracy: 1.0000\n",
      "Epoch 24: val_loss did not improve from 1.02096\n",
      "15/15 [==============================] - 1s 70ms/step - loss: 0.0205 - accuracy: 1.0000 - val_loss: 1.1872 - val_accuracy: 0.6167 - lr: 3.0000e-04\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0150 - accuracy: 1.0000\n",
      "Epoch 25: val_loss did not improve from 1.02096\n",
      "15/15 [==============================] - 1s 71ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 1.0630 - val_accuracy: 0.6500 - lr: 3.0000e-04\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0106 - accuracy: 1.0000\n",
      "Epoch 26: val_loss improved from 1.02096 to 0.98333, saving model to cnn_bilstm_best.h5\n",
      "15/15 [==============================] - 1s 87ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.9833 - val_accuracy: 0.6833 - lr: 3.0000e-04\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0085 - accuracy: 1.0000\n",
      "Epoch 27: val_loss improved from 0.98333 to 0.96536, saving model to cnn_bilstm_best.h5\n",
      "15/15 [==============================] - 1s 81ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.9654 - val_accuracy: 0.6667 - lr: 3.0000e-04\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0081 - accuracy: 1.0000\n",
      "Epoch 28: val_loss improved from 0.96536 to 0.90749, saving model to cnn_bilstm_best.h5\n",
      "15/15 [==============================] - 1s 80ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.9075 - val_accuracy: 0.7000 - lr: 3.0000e-04\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 29: val_loss improved from 0.90749 to 0.82103, saving model to cnn_bilstm_best.h5\n",
      "15/15 [==============================] - 1s 81ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.8210 - val_accuracy: 0.7167 - lr: 3.0000e-04\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0074 - accuracy: 1.0000\n",
      "Epoch 30: val_loss improved from 0.82103 to 0.77402, saving model to cnn_bilstm_best.h5\n",
      "15/15 [==============================] - 1s 89ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.7740 - val_accuracy: 0.7333 - lr: 3.0000e-04\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 31: val_loss did not improve from 0.77402\n",
      "15/15 [==============================] - 1s 76ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.7949 - val_accuracy: 0.8000 - lr: 3.0000e-04\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0066 - accuracy: 1.0000\n",
      "Epoch 32: val_loss did not improve from 0.77402\n",
      "15/15 [==============================] - 1s 82ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.8118 - val_accuracy: 0.8000 - lr: 3.0000e-04\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 33: val_loss did not improve from 0.77402\n",
      "15/15 [==============================] - 1s 76ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.8131 - val_accuracy: 0.7833 - lr: 3.0000e-04\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 34: val_loss did not improve from 0.77402\n",
      "\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
      "15/15 [==============================] - 1s 69ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.8663 - val_accuracy: 0.8000 - lr: 3.0000e-04\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 35: val_loss did not improve from 0.77402\n",
      "15/15 [==============================] - 1s 70ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.8880 - val_accuracy: 0.8333 - lr: 1.5000e-04\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 36: val_loss did not improve from 0.77402\n",
      "15/15 [==============================] - 1s 74ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.9528 - val_accuracy: 0.8167 - lr: 1.5000e-04\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 37: val_loss did not improve from 0.77402\n",
      "15/15 [==============================] - 1s 67ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.9635 - val_accuracy: 0.8167 - lr: 1.5000e-04\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 38: val_loss did not improve from 0.77402\n",
      "\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 7.500000356230885e-05.\n",
      "15/15 [==============================] - 1s 67ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.9855 - val_accuracy: 0.8000 - lr: 1.5000e-04\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 39: val_loss did not improve from 0.77402\n",
      "15/15 [==============================] - 1s 70ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.9964 - val_accuracy: 0.8000 - lr: 7.5000e-05\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 40: val_loss did not improve from 0.77402\n",
      "15/15 [==============================] - 1s 72ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.0083 - val_accuracy: 0.7833 - lr: 7.5000e-05\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 41: val_loss did not improve from 0.77402\n",
      "15/15 [==============================] - 1s 68ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.0326 - val_accuracy: 0.8167 - lr: 7.5000e-05\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 42: val_loss did not improve from 0.77402\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 3.7500001781154424e-05.\n",
      "15/15 [==============================] - 1s 72ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.0546 - val_accuracy: 0.8000 - lr: 7.5000e-05\n",
      "Epoch 42: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=100,\n",
    "    callbacks=cbs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "49479a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 3s 30ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_probs = model.predict(test_ds)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313751f7",
   "metadata": {},
   "source": [
    "## **Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1a42c137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8333\n",
      "Test Precision: 0.8441\n",
      "Test Recall: 0.8333\n",
      "Test F1-Score: 0.8302\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "disappointed       0.71      0.50      0.59        10\n",
      "     disgust       0.64      0.90      0.75        10\n",
      "       happy       0.92      1.00      0.96        12\n",
      "     neutral       1.00      0.83      0.91        12\n",
      "    surprise       0.88      0.88      0.88        16\n",
      "\n",
      "    accuracy                           0.83        60\n",
      "   macro avg       0.83      0.82      0.82        60\n",
      "weighted avg       0.84      0.83      0.83        60\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracy_score_val = accuracy_score(y_test, y_pred)\n",
    "precision_score_val = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "recall_score_val = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "f1_score_val = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy_score_val:.4f}\")\n",
    "print(f\"Test Precision: {precision_score_val:.4f}\")\n",
    "print(f\"Test Recall: {recall_score_val:.4f}\")\n",
    "print(f\"Test F1-Score: {f1_score_val:.4f}\")\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=le.classes_))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', xticklabels=le.classes_, yticklabels=le.classes_, cmap='Blues')\n",
    "plt.ylabel('True'); plt.xlabel('Pred')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b6f5b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-audio-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
